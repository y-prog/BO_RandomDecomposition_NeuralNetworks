{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd023557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (256, 4)\n",
      "Shape of y_binary: (256,)\n",
      "opt ======== <mcbo.optimizers.bo_base.BoBase object at 0x000001F5B4071FD0>\n",
      "0.6822494919619392 loss_fn_res\n",
      "0.49907560934653544 loss_fn_res\n",
      "1.2970698714588826 loss_fn_res\n",
      "0.47953216374269003 loss_fn_res\n",
      "0.47953216374269003 loss_fn_res\n",
      "0.47953216374269003 loss_fn_res\n",
      "0.5652396757185211 loss_fn_res\n",
      "0.5243394585784124 loss_fn_res\n",
      "0.47962976368050947 loss_fn_res\n",
      "0.6323438380110376 loss_fn_res\n",
      "3.5775019483023844 loss_fn_res\n",
      "1.2572071585526872 loss_fn_res\n",
      "2.784668131112913 loss_fn_res\n",
      "0.4954974940657148 loss_fn_res\n",
      "0.4811399983779888 loss_fn_res\n",
      "3.9970841477920453 loss_fn_res\n",
      "1.1210247658248802 loss_fn_res\n",
      "0.47953216374269003 loss_fn_res\n",
      "1.0235441438800346 loss_fn_res\n",
      "0.47953216374269003 loss_fn_res\n",
      "0.5248574722131782 loss_fn_res\n",
      "0.49184974223258354 loss_fn_res\n",
      "2.921021023479918 loss_fn_res\n",
      "1.3175721091554966 loss_fn_res\n",
      "0.5840258434174649 loss_fn_res\n",
      "0.9214646593969799 loss_fn_res\n",
      "2.0464080251177714 loss_fn_res\n",
      "0.6441819266284959 loss_fn_res\n",
      "0.47953216374269003 loss_fn_res\n",
      "0.47953216374269003 loss_fn_res\n",
      "1.5831845765386994 loss_fn_res\n",
      "0.5658730338368089 loss_fn_res\n",
      "0.6036358450656747 loss_fn_res\n",
      "1.6215785914299718 loss_fn_res\n",
      "0.47953216374269003 loss_fn_res\n",
      "0.47953216374269003 loss_fn_res\n",
      "0.4859774234197305 loss_fn_res\n",
      "0.5405103231186869 loss_fn_res\n",
      "0.7084070700031417 loss_fn_res\n",
      "0.4796290603035901 loss_fn_res\n",
      "0.6875867417255613 loss_fn_res\n",
      "0.6966668313472245 loss_fn_res\n",
      "3.456807324492319 loss_fn_res\n",
      "0.9658691268570332 loss_fn_res\n",
      "0.48451816383486773 loss_fn_res\n",
      "2.6925197167861166 loss_fn_res\n",
      "0.47960752907845716 loss_fn_res\n",
      "0.47953216374269003 loss_fn_res\n",
      "0.47953216374269003 loss_fn_res\n",
      "1.2365813783984103 loss_fn_res\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 68\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt ========\u001b[39m\u001b[38;5;124m'\u001b[39m, opt)\n\u001b[0;32m     66\u001b[0m weight_bias_optimizer \u001b[38;5;241m=\u001b[39m WeightAndBiasOptimizer(task\u001b[38;5;241m=\u001b[39mtask, optimizer\u001b[38;5;241m=\u001b[39mopt)\n\u001b[1;32m---> 68\u001b[0m best_results \u001b[38;5;241m=\u001b[39m \u001b[43mweight_bias_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_best_weights_and_biases\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_results, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest res\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\Skrivbord\\python_projects\\HEBO\\MCBO\\BO_pipeline.py:40\u001b[0m, in \u001b[0;36mWeightAndBiasOptimizer.find_best_weights_and_biases\u001b[1;34m(self, layers_list, epochs, X_data, y_data, loss_fn)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m#print(output_forward_prop, 'output_forward_prop')\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''if accuracy > best_accuracy:\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m        best_accuracy = accuracy\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m        best_num_correct = num_correct\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m        best_weights_and_biases = weights_and_biases'''\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_weights_and_biases, \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloss_fn_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "from BO_methods import CustomTask  # Import CustomTask from BO_methods module\n",
    "from config_NN_methods import flex_NN, activation_functions, loss_functions\n",
    "from BO_pipeline import WeightAndBiasOptimizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mcbo.optimizers.bo_builder import BoBuilder\n",
    "import numpy as np\n",
    "\n",
    "# Define the Rastrigin function in 4 dimensions\n",
    "def rastrigin_4d(x, y, z, w, A=10):\n",
    "    return (4 * A + (x**2 - A * np.cos(2 * np.pi * x)) +\n",
    "            (y**2 - A * np.cos(2 * np.pi * y)) +\n",
    "            (z**2 - A * np.cos(2 * np.pi * z)) +\n",
    "            (w**2 - A * np.cos(2 * np.pi * w)))\n",
    "\n",
    "# Desired dataset length\n",
    "desired_length = 20\n",
    "\n",
    "# Calculate the number of points per dimension\n",
    "num_points_per_dimension = int(np.sqrt(desired_length))\n",
    "\n",
    "# Generate X coordinates with the calculated number of points\n",
    "x = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "y = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "z = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "w = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "X, Y, Z, W = np.meshgrid(x, y, z, w, indexing='ij')\n",
    "Z_rastrigin = rastrigin_4d(X, Y, Z, W)\n",
    "\n",
    "# Flatten X, Y, Z, and W to create the dataset\n",
    "X = np.column_stack((X.flatten(), Y.flatten(), Z.flatten(), W.flatten()))\n",
    "\n",
    "# Define a binary threshold for the target variable\n",
    "threshold = np.mean(Z_rastrigin)  # You can adjust the threshold as needed\n",
    "\n",
    "# Generate the binary target variable based on the threshold\n",
    "y = (Z_rastrigin.flatten() > threshold).astype(int)\n",
    "\n",
    "# Display the shapes of X and y\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y_binary:\", y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# Usage:\n",
    "layer_sizes = [4,5,3,1]   # Define your layer sizes\n",
    "\n",
    "flex_NN_obj = flex_NN(layer_sizes, X_train, y_train)\n",
    "activation_obj = activation_functions()\n",
    "\n",
    "parameters = flex_NN_obj.label_parameters()\n",
    "\n",
    "hidden_activation = activation_obj.relu\n",
    "output_activation = activation_obj.sigmoid\n",
    "loss_fn= loss_functions(y_train).binary_cross_entropy\n",
    "\n",
    "task = CustomTask(layer_sizes, X_train, y_train)  # Instantiate CustomTask from BO_methods module\n",
    "searchspace = task.get_search_space()\n",
    "\n",
    "optimizer_builder = BoBuilder(model_id='gp_rd', acq_opt_id='is', acq_func_id='ei', tr_id='basic')\n",
    "opt = optimizer_builder.build_bo(search_space=searchspace, n_init=100)\n",
    "print('opt ========', opt)\n",
    "\n",
    "weight_bias_optimizer = WeightAndBiasOptimizer(task=task, optimizer=opt)\n",
    "\n",
    "best_results = weight_bias_optimizer.find_best_weights_and_biases(\n",
    "                                layer_sizes, 50, X_train, y_train, loss_fn)\n",
    "print(best_results, 'best res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12916bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4235a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (256, 4)\n",
      "Shape of y: (256,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc5b30ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30.31763724, 26.82654002, 26.82654002, 30.31763724, 26.82654002,\n",
       "       23.3354428 , 23.3354428 , 26.82654002, 26.82654002, 23.3354428 ,\n",
       "       23.3354428 , 26.82654002, 30.31763724, 26.82654002, 26.82654002,\n",
       "       30.31763724, 26.82654002, 23.3354428 , 23.3354428 , 26.82654002,\n",
       "       23.3354428 , 19.84434557, 19.84434557, 23.3354428 , 23.3354428 ,\n",
       "       19.84434557, 19.84434557, 23.3354428 , 26.82654002, 23.3354428 ,\n",
       "       23.3354428 , 26.82654002, 26.82654002, 23.3354428 , 23.3354428 ,\n",
       "       26.82654002, 23.3354428 , 19.84434557, 19.84434557, 23.3354428 ,\n",
       "       23.3354428 , 19.84434557, 19.84434557, 23.3354428 , 26.82654002,\n",
       "       23.3354428 , 23.3354428 , 26.82654002, 30.31763724, 26.82654002,\n",
       "       26.82654002, 30.31763724, 26.82654002, 23.3354428 , 23.3354428 ,\n",
       "       26.82654002, 26.82654002, 23.3354428 , 23.3354428 , 26.82654002,\n",
       "       30.31763724, 26.82654002, 26.82654002, 30.31763724, 26.82654002,\n",
       "       23.3354428 , 23.3354428 , 26.82654002, 23.3354428 , 19.84434557,\n",
       "       19.84434557, 23.3354428 , 23.3354428 , 19.84434557, 19.84434557,\n",
       "       23.3354428 , 26.82654002, 23.3354428 , 23.3354428 , 26.82654002,\n",
       "       23.3354428 , 19.84434557, 19.84434557, 23.3354428 , 19.84434557,\n",
       "       16.35324835, 16.35324835, 19.84434557, 19.84434557, 16.35324835,\n",
       "       16.35324835, 19.84434557, 23.3354428 , 19.84434557, 19.84434557,\n",
       "       23.3354428 , 23.3354428 , 19.84434557, 19.84434557, 23.3354428 ,\n",
       "       19.84434557, 16.35324835, 16.35324835, 19.84434557, 19.84434557,\n",
       "       16.35324835, 16.35324835, 19.84434557, 23.3354428 , 19.84434557,\n",
       "       19.84434557, 23.3354428 , 26.82654002, 23.3354428 , 23.3354428 ,\n",
       "       26.82654002, 23.3354428 , 19.84434557, 19.84434557, 23.3354428 ,\n",
       "       23.3354428 , 19.84434557, 19.84434557, 23.3354428 , 26.82654002,\n",
       "       23.3354428 , 23.3354428 , 26.82654002, 26.82654002, 23.3354428 ,\n",
       "       23.3354428 , 26.82654002, 23.3354428 , 19.84434557, 19.84434557,\n",
       "       23.3354428 , 23.3354428 , 19.84434557, 19.84434557, 23.3354428 ,\n",
       "       26.82654002, 23.3354428 , 23.3354428 , 26.82654002, 23.3354428 ,\n",
       "       19.84434557, 19.84434557, 23.3354428 , 19.84434557, 16.35324835,\n",
       "       16.35324835, 19.84434557, 19.84434557, 16.35324835, 16.35324835,\n",
       "       19.84434557, 23.3354428 , 19.84434557, 19.84434557, 23.3354428 ,\n",
       "       23.3354428 , 19.84434557, 19.84434557, 23.3354428 , 19.84434557,\n",
       "       16.35324835, 16.35324835, 19.84434557, 19.84434557, 16.35324835,\n",
       "       16.35324835, 19.84434557, 23.3354428 , 19.84434557, 19.84434557,\n",
       "       23.3354428 , 26.82654002, 23.3354428 , 23.3354428 , 26.82654002,\n",
       "       23.3354428 , 19.84434557, 19.84434557, 23.3354428 , 23.3354428 ,\n",
       "       19.84434557, 19.84434557, 23.3354428 , 26.82654002, 23.3354428 ,\n",
       "       23.3354428 , 26.82654002, 30.31763724, 26.82654002, 26.82654002,\n",
       "       30.31763724, 26.82654002, 23.3354428 , 23.3354428 , 26.82654002,\n",
       "       26.82654002, 23.3354428 , 23.3354428 , 26.82654002, 30.31763724,\n",
       "       26.82654002, 26.82654002, 30.31763724, 26.82654002, 23.3354428 ,\n",
       "       23.3354428 , 26.82654002, 23.3354428 , 19.84434557, 19.84434557,\n",
       "       23.3354428 , 23.3354428 , 19.84434557, 19.84434557, 23.3354428 ,\n",
       "       26.82654002, 23.3354428 , 23.3354428 , 26.82654002, 26.82654002,\n",
       "       23.3354428 , 23.3354428 , 26.82654002, 23.3354428 , 19.84434557,\n",
       "       19.84434557, 23.3354428 , 23.3354428 , 19.84434557, 19.84434557,\n",
       "       23.3354428 , 26.82654002, 23.3354428 , 23.3354428 , 26.82654002,\n",
       "       30.31763724, 26.82654002, 26.82654002, 30.31763724, 26.82654002,\n",
       "       23.3354428 , 23.3354428 , 26.82654002, 26.82654002, 23.3354428 ,\n",
       "       23.3354428 , 26.82654002, 30.31763724, 26.82654002, 26.82654002,\n",
       "       30.31763724])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "012db619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "tuplist=[(1.5069097691724593, 0.47953216374269003), (0.8378851457703783, 0.4853801169590643), (0.48158686060724276, 0.5380116959064327), (0.5009386057970251, 0.543859649122807), (0.47953216374269003, 0.52046783625731), (2.7475563074094937, 0.47953216374269003), (0.47953216374269003, 0.52046783625731), (0.48076710814896173, 0.52046783625731), (1.0324533944223198, 0.5321637426900585), (0.6935009072824552, 0.5087719298245614), (4.932884130109292, 0.47953216374269003), (1.619861034188546, 0.47953216374269003), (0.7586152223361972, 0.52046783625731), (0.4901416225317821, 0.5146198830409356), (4.73457474539051, 0.47953216374269003), (0.5406980654219755, 0.47953216374269003), (0.4801969891791217, 0.52046783625731), (0.570193483921365, 0.5380116959064327), (0.6302493867029312, 0.5263157894736842), (1.1976873476036127, 0.49122807017543857), (0.6962633249547566, 0.5906432748538012), (0.5160147192161512, 0.543859649122807), (1.1513795086326608, 0.5847953216374269), (0.48203672401104375, 0.52046783625731), (0.47953216374269003, 0.52046783625731), (0.47953826317520876, 0.52046783625731), (1.0508890184199362, 0.4619883040935672), (0.490723128380327, 0.4269005847953216), (1.3556164387130107, 0.5087719298245614), (2.306081307548938, 0.49122807017543857), (0.566662946698863, 0.5906432748538012), (0.5053346736819235, 0.543859649122807), (0.8358481543460241, 0.5087719298245614), (0.6879447794896609, 0.47953216374269003), (0.6159596336769803, 0.47953216374269003), (0.4829026051185236, 0.52046783625731), (0.4861075132396454, 0.543859649122807), (0.5122212457798326, 0.5906432748538012), (0.9817718771417961, 0.4502923976608187), (0.6573301873559265, 0.4327485380116959), (1.908777434935382, 0.5087719298245614), (0.6812190544434177, 0.5087719298245614), (0.732839866075264, 0.6023391812865497), (2.043599203439226, 0.4444444444444444), (0.4819035366759154, 0.52046783625731), (1.0750944214041596, 0.5672514619883041), (0.8717795073296406, 0.5146198830409356), (0.5973367842458589, 0.47953216374269003), (1.9447424716125934, 0.43859649122807015), (0.7678469306835635, 0.52046783625731)] \n",
    "tuplist0=[i[0] for i in tuplist]\n",
    "tuplist1=[i[1] for i in tuplist]\n",
    "print(tuplist0.index( min(tuplist0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1de23e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47953216374269003, 0.52046783625731)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuplist[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32e8e225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6023391812865497"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tuplist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ec5b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (256, 4)\n",
      "Shape of y_binary: (256,)\n",
      "((171, 171), (1, 3))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (171,171) and (1,3) not aligned: 171 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 104\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Create and train the neural network\u001b[39;00m\n\u001b[0;32m    103\u001b[0m nn \u001b[38;5;241m=\u001b[39m flex_NN(layers_sizes, learning_rate)\n\u001b[1;32m--> 104\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m    107\u001b[0m predictions \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mforward_propagation(X_train)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[13], line 45\u001b[0m, in \u001b[0;36mflex_NN.train\u001b[1;34m(self, X, y, epochs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     44\u001b[0m     activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_propagation(X)\n\u001b[1;32m---> 45\u001b[0m     grads_weights, grads_biases \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_parameters(grads_weights, grads_biases)\n",
      "Cell \u001b[1;32mIn[13], line 34\u001b[0m, in \u001b[0;36mflex_NN.backward_propagation\u001b[1;34m(self, X, y, activations)\u001b[0m\n\u001b[0;32m     32\u001b[0m     grads_biases[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dZ, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m((dZ\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[i]\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m---> 34\u001b[0m     dA \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads_weights, grads_biases\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (171,171) and (1,3) not aligned: 171 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class flex_NN:\n",
    "    def __init__(self, layers_sizes, learning_rate=0.1):\n",
    "        self.layers_sizes = layers_sizes\n",
    "        self.num_layers = len(layers_sizes)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights, self.biases = self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        weights = [np.random.randn(self.layers_sizes[i], self.layers_sizes[i+1]) for i in range(self.num_layers-1)]\n",
    "        biases = [np.random.randn(1, self.layers_sizes[i+1]) for i in range(self.num_layers-1)]\n",
    "        return weights, biases\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        activations = [X]\n",
    "        for i in range(self.num_layers - 1):\n",
    "            Z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
    "            A = self.sigmoid(Z)\n",
    "            activations.append(A)\n",
    "        return activations\n",
    "\n",
    "    def backward_propagation(self, X, y, activations):\n",
    "        m = X.shape[0]\n",
    "        grads_weights = [np.zeros_like(weight) for weight in self.weights]\n",
    "        grads_biases = [np.zeros_like(bias) for bias in self.biases]\n",
    "\n",
    "        dA = (activations[-1] - y) / m\n",
    "        for i in range(self.num_layers - 2, -1, -1):\n",
    "            dZ = np.multiply(dA, self.sigmoid_derivative(activations[i+1]))\n",
    "            grads_weights[i] = np.dot(activations[i].T, dZ)\n",
    "            grads_biases[i] = np.sum(dZ, axis=0, keepdims=True)\n",
    "            print((dZ.shape, self.weights[i].T.shape))\n",
    "            dA = np.dot(dZ, self.weights[i].T)\n",
    "        return grads_weights, grads_biases\n",
    "\n",
    "    def update_parameters(self, grads_weights, grads_biases):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * grads_weights[i]\n",
    "            self.biases[i] -= self.learning_rate * grads_biases[i]\n",
    "\n",
    "    def train(self, X, y, epochs=100):\n",
    "        for epoch in range(epochs):\n",
    "            activations = self.forward_propagation(X)\n",
    "            grads_weights, grads_biases = self.backward_propagation(X, y, activations)\n",
    "            self.update_parameters(grads_weights, grads_biases)\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(Z):\n",
    "        return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(A):\n",
    "        return np.multiply(A, 1 - A)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def rastrigin_4d(x, y, z, w, A=10):\n",
    "    return (4 * A + (x**2 - A * np.cos(2 * np.pi * x)) +\n",
    "            (y**2 - A * np.cos(2 * np.pi * y)) +\n",
    "            (z**2 - A * np.cos(2 * np.pi * z)) +\n",
    "            (w**2 - A * np.cos(2 * np.pi * w)))\n",
    "\n",
    "# Desired dataset length\n",
    "desired_length = 20\n",
    "\n",
    "# Calculate the number of points per dimension\n",
    "num_points_per_dimension = int(np.sqrt(desired_length))\n",
    "\n",
    "# Generate X coordinates with the calculated number of points\n",
    "x = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "y = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "z = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "w = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "X, Y, Z, W = np.meshgrid(x, y, z, w, indexing='ij')\n",
    "Z_rastrigin = rastrigin_4d(X, Y, Z, W)\n",
    "\n",
    "# Flatten X, Y, Z, and W to create the dataset\n",
    "X = np.column_stack((X.flatten(), Y.flatten(), Z.flatten(), W.flatten()))\n",
    "\n",
    "# Define a binary threshold for the target variable\n",
    "threshold = np.mean(Z_rastrigin)  # You can adjust the threshold as needed\n",
    "\n",
    "# Generate the binary target variable based on the threshold\n",
    "y = (Z_rastrigin.flatten() > threshold).astype(int)\n",
    "\n",
    "# Display the shapes of X and y\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y_binary:\", y.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "layers_sizes = [4,5, 3, 1]  \n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 50\n",
    "\n",
    "# Create and train the neural network\n",
    "nn = flex_NN(layers_sizes, learning_rate)\n",
    "nn.train(X_train, y_train, epochs)\n",
    "\n",
    "# Make predictions\n",
    "predictions = nn.forward_propagation(X_train)[-1]\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "032793e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (256, 4)\n",
      "Shape of y_binary: (256,)\n",
      "Shape of X_train: (171, 4)\n",
      "Shape of y_train: (171,)\n",
      "Shape of X_test: (85, 4)\n",
      "Shape of y_test: (85,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (171,171) and (1,3) not aligned: 171 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 102\u001b[0m\n\u001b[0;32m    100\u001b[0m activations \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mforward_propagation(X_train)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# Backward propagation\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m grads_weights, grads_biases \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_propagation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[0;32m    104\u001b[0m nn\u001b[38;5;241m.\u001b[39mupdate_parameters(grads_weights, grads_biases)\n",
      "Cell \u001b[1;32mIn[28], line 73\u001b[0m, in \u001b[0;36mflex_NN.backward_propagation\u001b[1;34m(self, X, y, activations)\u001b[0m\n\u001b[0;32m     71\u001b[0m     grads_weights[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(activations[i]\u001b[38;5;241m.\u001b[39mT, dZ) \u001b[38;5;241m/\u001b[39m m\n\u001b[0;32m     72\u001b[0m     grads_biases[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dZ, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m/\u001b[39m m\n\u001b[1;32m---> 73\u001b[0m     dA \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdZ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grads_weights, grads_biases\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (171,171) and (1,3) not aligned: 171 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rastrigin_4d(x, y, z, w, A=10):\n",
    "    return (4 * A + (x**2 - A * np.cos(2 * np.pi * x)) +\n",
    "            (y**2 - A * np.cos(2 * np.pi * y)) +\n",
    "            (z**2 - A * np.cos(2 * np.pi * z)) +\n",
    "            (w**2 - A * np.cos(2 * np.pi * w)))\n",
    "\n",
    "# Desired dataset length\n",
    "desired_length = 20\n",
    "\n",
    "# Calculate the number of points per dimension\n",
    "num_points_per_dimension = int(np.sqrt(desired_length))\n",
    "\n",
    "# Generate X coordinates with the calculated number of points\n",
    "x = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "y = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "z = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "w = np.linspace(-5.12, 5.12, num_points_per_dimension)\n",
    "X, Y, Z, W = np.meshgrid(x, y, z, w, indexing='ij')\n",
    "Z_rastrigin = rastrigin_4d(X, Y, Z, W)\n",
    "\n",
    "# Flatten X, Y, Z, and W to create the dataset\n",
    "X = np.column_stack((X.flatten(), Y.flatten(), Z.flatten(), W.flatten()))\n",
    "\n",
    "# Define a binary threshold for the target variable\n",
    "threshold = np.mean(Z_rastrigin)  # You can adjust the threshold as needed\n",
    "\n",
    "# Generate the binary target variable based on the threshold\n",
    "y = (Z_rastrigin.flatten() > threshold).astype(int)\n",
    "\n",
    "# Display the shapes of X and y\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y_binary:\", y.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "class flex_NN:\n",
    "    def __init__(self, layers_sizes, learning_rate):\n",
    "        self.layers_sizes = layers_sizes\n",
    "        self.weights = [np.random.randn(layers_sizes[i], layers_sizes[i+1]) for i in range(len(layers_sizes) - 1)]\n",
    "        self.biases = [np.zeros((1, sizes[1])) for sizes in zip(layers_sizes[:-1], layers_sizes[1:])]\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        activations = [X]\n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            Z = np.dot(activations[-1], W) + b\n",
    "            A = self.sigmoid(Z)\n",
    "            activations.append(A)\n",
    "        return activations\n",
    "\n",
    "    \n",
    "\n",
    "    def backward_propagation(self, X, y, activations):\n",
    "        m = X.shape[0]\n",
    "        grads_weights = [np.empty_like(W) for W in self.weights]\n",
    "        grads_biases = [np.empty_like(b) for b in self.biases]\n",
    "        dA = activations[-1] - y\n",
    "\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dZ = np.multiply(dA, self.sigmoid_derivative(activations[i+1]))\n",
    "            grads_weights[i] = np.dot(activations[i].T, dZ) / m\n",
    "            grads_biases[i] = np.sum(dZ, axis=0, keepdims=True) / m\n",
    "            dA = np.dot(dZ, self.weights[i].T)\n",
    "\n",
    "        return grads_weights, grads_biases\n",
    "\n",
    "\n",
    "    def update_parameters(self, grads_weights, grads_biases):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.learning_rate * grads_weights[i]\n",
    "            self.biases[i] -= self.learning_rate * grads_biases[i]\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid_derivative(x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "# Example usage:\n",
    "layers_sizes = [4, 5, 3, 1]\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "# Create and train the neural network\n",
    "nn = flex_NN(layers_sizes, learning_rate)\n",
    "for epoch in range(epochs):\n",
    "    # Forward propagation\n",
    "    activations = nn.forward_propagation(X_train)\n",
    "    # Backward propagation\n",
    "    grads_weights, grads_biases = nn.backward_propagation(X_train, y_train, activations)\n",
    "    # Update parameters\n",
    "    nn.update_parameters(grads_weights, grads_biases)\n",
    "\n",
    "# Make predictions\n",
    "predictions = nn.forward_propagation(X_train)[-1]\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83eb7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
