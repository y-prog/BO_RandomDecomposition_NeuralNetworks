{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a6e84878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n",
      "(714, 12)\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.56049551 -0.36289572 -0.88321524 -0.86342803 -0.23101284  0.6152194\n",
      " -0.12242829 -0.56785653  0.65465394  0.60448644  0.04969671 -0.13961209\n",
      "  0.33939809  0.20906925 -0.81114384  0.24761332 -0.38244845  0.50323252\n",
      " -0.64815414  0.08490032  0.60629185 -0.79867567  0.00163409 -0.03092531\n",
      "  0.67534764]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.95251488 -0.16402395 -0.66503383 -0.43941628 -0.6774873   0.54821424\n",
      "  0.99939122 -0.16660144  0.81104076 -0.51313815 -0.86106594 -0.98681967\n",
      "  0.68326346  0.17708397  0.24027432  0.89290092  0.95750543 -0.34640099\n",
      " -0.07025511 -0.60217642 -0.45366679  0.27262163  0.03307865  0.4340762\n",
      "  0.23035162]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.36288348  0.42562151 -0.17118629 -0.92176884  0.64137602 -0.40427103\n",
      "  0.02812649 -0.24295391 -0.21447404 -0.35040987 -0.34777697  0.61524686\n",
      " -0.53263943  0.26139961  0.02681347 -0.79234583  0.86546217  0.17270494\n",
      "  0.2957745  -0.83013256  0.64095816  0.40517411 -0.92737052 -0.27606203\n",
      " -0.54535355]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.06496041 -0.98146634 -0.25509671 -0.97221973  0.1524965  -0.85089405\n",
      " -0.66576441  0.86059188 -0.37236761 -0.29408255 -0.82502662 -0.7543393\n",
      " -0.62463873 -0.68223466 -0.77218857 -0.31593232  0.1490202  -0.22127832\n",
      "  0.21718417  0.05418869  0.22321813  0.79819479  0.9130535  -0.29358551\n",
      "  0.74351706]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.96206723 -0.44721291 -0.16389679 -0.29324023 -0.81508007 -0.64699118\n",
      "  0.11174938 -0.42924296  0.90407182  0.82547695  0.97775824  0.01990901\n",
      " -0.97757795 -0.42858151  0.29820727 -0.7321266   0.96210968  0.4327997\n",
      " -0.85895589 -0.34641163 -0.25453714 -0.55135216 -0.65153312  0.51385278\n",
      "  0.60142412]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.76978144 -0.71525551 -0.58709019 -0.61035268  0.2977968  -0.81427533\n",
      " -0.54758847 -0.05841844  0.25526564  0.99786747 -0.54194818 -0.32754761\n",
      " -0.17607509 -0.58064244 -0.10688569  0.67102031  0.98239602 -0.67065016\n",
      " -0.87009513  0.51229802 -0.91878956  0.20843976  0.0766812   0.56008349\n",
      "  0.50729856]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.57766931 -0.74478163 -0.70099337 -0.46326829 -0.14985851 -0.51317514\n",
      "  0.27262568 -0.62553232 -0.23864703  0.5480086   0.27180084 -0.31582192\n",
      "  0.79887492  0.08100721 -0.5657699   0.76068548 -0.28812058 -0.48615027\n",
      "  0.93051566 -0.37161674 -0.53516231 -0.13348687 -0.20865078 -0.97120245\n",
      "  0.6952654 ]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.60908399  0.91808043  0.01838649  0.64189431  0.62277245 -0.08093545\n",
      "  0.87488035  0.04253248  0.58365544 -0.0313474  -0.4313098  -0.04527023\n",
      "  0.8059593  -0.07786862 -0.29323169  0.0026234  -0.10962491 -0.14787916\n",
      " -0.69638909  0.95743427  0.77814185 -0.23445669 -0.1688306  -0.71241905\n",
      "  0.23929936]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.86647338 -0.24687934  0.85610505 -0.67403981  0.83782919  0.81362121\n",
      "  0.57239715  0.71480834 -0.3910522  -0.97965236  0.30649243  0.99404621\n",
      " -0.74451374 -0.33941252 -0.01579579 -0.62678756  0.91812355  0.77882958\n",
      " -0.41107507  0.51704638  0.63594869 -0.78657289  0.28660033 -0.57380364\n",
      "  0.00287472]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.36832047  0.05417717 -0.21606108  0.56046673  0.20093163  0.74403751\n",
      " -0.45367262 -0.39192108 -0.64718483  0.39497611 -0.57919662 -0.18324064\n",
      " -0.59129504  0.57202962 -0.81689155 -0.74576206  0.2172524   0.14665158\n",
      "  0.53526896 -0.88461356  0.14970663 -0.73153334  0.32417735 -0.29679906\n",
      " -0.25212995]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.38437258  0.46764377 -0.91329357  0.35010125  0.46322564  0.43719963\n",
      " -0.40628275  0.62158414  0.08793927 -0.22127767  0.57054013 -0.63534154\n",
      " -0.18390534 -0.81205251  0.91521897  0.17632822 -0.57414183  0.93079224\n",
      " -0.18064585  0.01774548 -0.06735507  0.67397692 -0.69142277 -0.41710383\n",
      " -0.55247196]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 6.37952636e-01 -9.05105050e-01  4.12334686e-01 -3.47108950e-01\n",
      " -8.86818305e-01 -9.51775281e-01 -8.61423594e-01  8.22623164e-01\n",
      "  1.32424090e-01  2.65972940e-01 -7.78376794e-01  2.27212676e-01\n",
      "  5.61249090e-01  9.49793378e-01  3.31124312e-01  1.27526492e-02\n",
      "  3.78761337e-01 -7.93444629e-01 -6.37070293e-01  1.25241002e-01\n",
      "  2.94285359e-01  4.99506865e-01 -8.26693756e-04  3.37040097e-01\n",
      "  1.14823315e-01]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.48182892 -0.51795472 -0.41779019  0.09311229  0.12051091 -0.3172216\n",
      " -0.42826433 -0.85408422  0.65149296  0.21338793  0.7903008  -0.52742458\n",
      "  0.22370297 -0.76691184 -0.79493004  0.3895782  -0.58850764 -0.07964917\n",
      " -0.06553524  0.39060542 -0.06750374 -0.23531774  0.5809549   0.65627047\n",
      "  0.77898469]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.83516557  0.66429557 -0.50980999 -0.11112878  0.51067996  0.36469685\n",
      " -0.8147504   0.51284907 -0.08594529 -0.03833589  0.68084339 -0.78890173\n",
      "  0.02769949  0.54614163  0.64572437 -0.38958547 -0.32128451 -0.16184294\n",
      "  0.13789994 -0.00440641  0.28860968  0.65697316 -0.11342703 -0.61582604\n",
      "  0.18796358]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.72854952  0.72398123 -0.351484   -0.74320937 -0.0064757  -0.74194221\n",
      " -0.00110256 -0.48931313  0.62917308  0.8887748   0.35761469 -0.89965166\n",
      "  0.18386377 -0.26353962 -0.35489014 -0.19526401 -0.54487967  0.20041235\n",
      " -0.09446678 -0.0331128  -0.3851918  -0.83846763 -0.66839106  0.12596012\n",
      "  0.83921372]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.98922303 -0.25409816  0.44763105  0.81437064  0.18710018  0.6021757\n",
      "  0.41669416 -0.64934467 -0.37735464 -0.95370731 -0.86517075 -0.95423745\n",
      " -0.80760061  0.73052446  0.19359907 -0.95727785 -0.51003957  0.62392922\n",
      "  0.83789215 -0.26412278  0.67699444  0.24954783 -0.37356611 -0.2643675\n",
      " -0.28616526]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.63477717 -0.2502768   0.63763877  0.13923594  0.79789637  0.82914736\n",
      "  0.50236232  0.20224478  0.1507364   0.42426497 -0.58286194 -0.1376707\n",
      " -0.04467272 -0.8516601  -0.44571432  0.22028609 -0.99068884  0.68289605\n",
      " -0.43060141 -0.45707723  0.40383579  0.73635211 -0.57524087  0.01155575\n",
      "  0.39027595]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.3904764   0.51379375  0.17611213  0.76048009 -0.60380086 -0.29179111\n",
      " -0.88094154  0.41120523 -0.58305444 -0.18032026  0.71872319 -0.14654844\n",
      "  0.98412658 -0.25055658  0.46681189 -0.15371296  0.76141766  0.34038922\n",
      "  0.32266432  0.89240042 -0.34004874  0.67772846 -0.74836506  0.24151568\n",
      "  0.29733094]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.27245173 -0.40985955 -0.35504249  0.64765302 -0.80350698  0.41168612\n",
      " -0.3200882  -0.21047803 -0.2291081   0.4275809  -0.75605113 -0.6289092\n",
      " -0.82310771 -0.32911319  0.44601795  0.83952927 -0.40801901  0.28307273\n",
      " -0.77541056 -0.36480666  0.66133223 -0.25443448 -0.24483775  0.78719964\n",
      "  0.34086769]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.46609437 -0.76581184 -0.37904353 -0.84044815  0.38128723 -0.70359173\n",
      " -0.42365647 -0.92165259  0.7150794   0.3504393  -0.68813581  0.56803811\n",
      "  0.03849336  0.98631408  0.10408691  0.2835726  -0.82725124  0.89805908\n",
      " -0.21542908 -0.87315735 -0.02531494  0.49046771  0.08187249 -0.61541466\n",
      "  0.29008402]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.06921011 -0.4849291  -0.7513833  -0.58545867  0.64569781  0.3816329\n",
      " -0.79139935  0.81740905 -0.56802361 -0.97952399  0.08800665 -0.74145874\n",
      " -0.40870148  0.97109799 -0.51814882 -0.20261102 -0.82602519 -0.2326252\n",
      "  0.4819865  -0.66543052 -0.65072227 -0.14506371 -0.85449695 -0.82598683\n",
      " -0.55669065]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.85214327 -0.22531054  0.8666021  -0.70947777  0.70098038 -0.95708918\n",
      " -0.27505738  0.46149383  0.62047893 -0.42932301 -0.45164512  0.83063439\n",
      "  0.07982659 -0.62039208 -0.49259238 -0.47282164  0.11203655  0.66556663\n",
      " -0.55036612  0.71455327 -0.84457508  0.68027633  0.20764674  0.25442384\n",
      " -0.7128182 ]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.68319045 -0.89559058  0.2762788   0.66155907  0.28328899 -0.69845699\n",
      " -0.40135978 -0.45666639 -0.43425668 -0.62181696 -0.5558486   0.17515196\n",
      "  0.14763752  0.25989392 -0.23427441  0.81056989  0.9858411   0.84300745\n",
      "  0.17954209  0.17326692  0.3992115   0.0615239   0.98604888 -0.2117383\n",
      "  0.95725651]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.92174871 -0.04263949 -0.94605076  0.72489325  0.66642684  0.41976289\n",
      "  0.26899846 -0.00627229 -0.93102056 -0.66602729  0.15162686 -0.94476725\n",
      "  0.1549458   0.07103884 -0.70997567 -0.96746985 -0.70995507 -0.01692151\n",
      " -0.69312594  0.5575611   0.73024161  0.5297141   0.92824986 -0.67419461\n",
      " -0.90940974]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.18896631  0.48001503  0.32473419  0.05594302  0.40132841  0.42370045\n",
      "  0.76660533 -0.94441442 -0.78013086  0.45695337 -0.25484665  0.92594525\n",
      "  0.70441757 -0.69125302 -0.32468857 -0.34617507 -0.80075644  0.45820516\n",
      " -0.79459662  0.61756309  0.61488398 -0.84285684  0.65834696 -0.76582567\n",
      " -0.06452703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating with parameters:\n",
      "x_ind: [-0.55037504  0.02749029 -0.10569315 -0.79164385 -0.82524617  0.28232541\n",
      " -0.09031656 -0.32143444  0.49175909 -0.5208973  -0.71888021 -0.38411748\n",
      " -0.22050517 -0.66444059  0.3687092   0.88701117 -0.12339224 -0.24596029\n",
      "  0.0464655   0.64647288  0.31130206  0.18005194 -0.46731777  0.11781957\n",
      " -0.14983937]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.96137249 -0.85620932  0.94511593 -0.72876676  0.52408702 -0.04527195\n",
      "  0.49333035  0.04507047 -0.47585815 -0.05052477  0.06970754 -0.10005008\n",
      "  0.03270833  0.97850346  0.66169056  0.30806601  0.12666251 -0.68224197\n",
      "  0.35002199  0.10122742 -0.71724989  0.10056835 -0.95518481 -0.39905881\n",
      " -0.27996208]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.52540193 -0.11970074  0.63813765  0.62709762 -0.64128062  0.34981618\n",
      " -0.70797927  0.03444723  0.30829118 -0.50602201 -0.22597519 -0.43146261\n",
      " -0.9781432  -0.09454001 -0.33483542  0.06543814 -0.41123928  0.17300776\n",
      " -0.77326587 -0.64575881 -0.81191185  0.21995344  0.66708341  0.99485276\n",
      "  0.56396771]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.39983755  0.41780922 -0.65736849  0.85838027 -0.52678131  0.5476016\n",
      "  0.78993276 -0.58363024  0.39839781  0.16046765  0.46903355  0.4568426\n",
      "  0.5791012  -0.74839742 -0.53281948 -0.59293056 -0.39495581 -0.6070567\n",
      "  0.8355525  -0.7035345  -0.30994075  0.39128322 -0.88855954 -0.18819836\n",
      "  0.49070058]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.82317878 -0.88380669  0.44022224 -0.60104863 -0.21069875  0.93296332\n",
      " -0.69481052  0.55349473 -0.30976307  0.44114754 -0.79448912 -0.02863956\n",
      " -0.48102459 -0.57041992  0.66528516  0.66674955 -0.151047   -0.08480174\n",
      " -0.54845547  0.14796884  0.70982178  0.83621794 -0.58874384 -0.57542678\n",
      "  0.81044985]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.81297387 -0.88030562 -0.02886799 -0.97772485 -0.37086587  0.77728206\n",
      " -0.61579764 -0.40227568 -0.05016203 -0.33785052  0.24122649 -0.73525408\n",
      "  0.63311005 -0.46330387  0.78140805 -0.59160187 -0.37170877  0.74575863\n",
      " -0.76004938 -0.26697129  0.92347254  0.57136416  0.08890643  0.25769809\n",
      " -0.20902495]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.10651837 -0.25879719 -0.62590967 -0.33809419 -0.35669652  0.58906841\n",
      " -0.78707239  0.16082005 -0.19246582  0.2060417  -0.12701335 -0.7915921\n",
      " -0.46872267  0.02183453 -0.17995695 -0.50349294  0.83066317 -0.82796362\n",
      " -0.59460218  0.11609648 -0.51727829 -0.56072402 -0.64324392 -0.51149022\n",
      "  0.12835906]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.3910625  -0.61007207  0.39747981 -0.93900122 -0.66148095  0.38951503\n",
      " -0.380641   -0.45695555  0.89469799  0.64970955 -0.18787625  0.45075083\n",
      " -0.97842301 -0.32890374 -0.94619169 -0.61629771 -0.91609086 -0.93914293\n",
      " -0.66085509 -0.00304431  0.52419134  0.65179254  0.66757666 -0.01182791\n",
      "  0.78461409]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.44723836  0.86956158  0.09477516  0.65594983 -0.41225791  0.14831109\n",
      "  0.10482089 -0.14966425 -0.36010228 -0.81155143 -0.53542462 -0.52583719\n",
      " -0.69033736 -0.08997643  0.38992324 -0.68370108 -0.53085968  0.21295569\n",
      " -0.8186507   0.20439616  0.14773843 -0.75584064  0.55431939 -0.03484763\n",
      "  0.98769613]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.13979408  0.16268721 -0.93925224 -0.01697549 -0.96067482 -0.75878235\n",
      "  0.97598822 -0.58497075 -0.63335392  0.4213412  -0.93914794 -0.72441325\n",
      "  0.97136581 -0.6670009   0.56806647  0.90662499  0.61710559 -0.33787735\n",
      "  0.59567847 -0.93577642 -0.93638527  0.24439717  0.51153901 -0.09288474\n",
      "  0.93858872]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.43049685 -0.4253492   0.2931759   0.28372156 -0.05417811 -0.66888632\n",
      "  0.58673607  0.26601559 -0.26881431 -0.35371011  0.69537839 -0.00114481\n",
      " -0.36039751 -0.34654262 -0.96395149  0.20406319  0.66791625 -0.16412459\n",
      " -0.00892445 -0.93432664  0.0858327   0.76550762  0.63225523  0.59217139\n",
      "  0.43568774]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.67543849  0.40955346  0.26997418 -0.17703025  0.53718192  0.64055912\n",
      " -0.23912839 -0.14883128  0.33903142 -0.75470009 -0.34717983  0.60553058\n",
      " -0.7823522  -0.85936681  0.19006171  0.27567426 -0.77688984 -0.18857882\n",
      " -0.22296112  0.44319034  0.61188081 -0.79775589 -0.56059644 -0.566774\n",
      " -0.71354488]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.0950003  -0.2501419  -0.71182968 -0.30898491  0.72449474  0.60662582\n",
      "  0.15169212 -0.96776539  0.39472538  0.09130842  0.36218208 -0.44243451\n",
      " -0.76248239  0.77942055  0.17673752  0.90865093  0.9475269  -0.82675954\n",
      "  0.90125585 -0.61374551 -0.44775443  0.69938531  0.45778475  0.80861461\n",
      " -0.95362798]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.49571444 -0.73576871 -0.30202455 -0.55559917  0.64085712  0.22891785\n",
      "  0.24661606 -0.94367001  0.84811463 -0.54747536  0.8951748  -0.44713678\n",
      " -0.37931457 -0.60249505 -0.24258418 -0.53884989  0.3867097  -0.99286713\n",
      " -0.25798323  0.30439692  0.79472325  0.59724147 -0.28943699  0.58268101\n",
      "  0.65043671]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.39643406 -0.52553554  0.17179794  0.54106509 -0.16708456 -0.12231973\n",
      "  0.64545444 -0.05773136  0.76350897  0.64272359  0.1299806   0.66776252\n",
      " -0.92470992  0.51380027  0.49953465 -0.98816492 -0.45481389  0.79684649\n",
      " -0.66605455  0.09315182 -0.52747919  0.00755087  0.33368952 -0.33375527\n",
      "  0.68188405]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.57390651  0.28549457 -0.72243397  0.39109517  0.46085296 -0.9479347\n",
      "  0.47290357 -0.63354827 -0.42335896 -0.91420818 -0.20570619 -0.70433241\n",
      "  0.02297718 -0.30089642 -0.14364192  0.1977673  -0.08792427 -0.56440288\n",
      " -0.45191422  0.96358894 -0.84705373 -0.3822048  -0.75595654 -0.63879499\n",
      "  0.49272182]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.62537251 -0.89624779  0.70544676 -0.27854203 -0.42421845 -0.34564611\n",
      "  0.13858225  0.1700841  -0.0896735  -0.80269421 -0.46345287  0.23345518\n",
      " -0.57251817 -0.05120536  0.3535519   0.01568971 -0.40572276 -0.14784202\n",
      " -0.52206693  0.67081176 -0.68012138 -0.18912354  0.41117316 -0.44092995\n",
      " -0.44015303]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.28225454 -0.45462192 -0.94502791 -0.35776773 -0.88887505 -0.15872068\n",
      "  0.33836605 -0.18361644  0.49453798  0.04199225  0.86808759  0.91002697\n",
      "  0.03862128 -0.41747792  0.03423461 -0.04469925 -0.6999555   0.94385159\n",
      " -0.00251744 -0.17373096  0.67400574  0.93731627  0.94421546 -0.33472751\n",
      "  0.27963572]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.92824064 -0.58337704 -0.79432517 -0.99751424  0.35194305 -0.02836743\n",
      "  0.49183522  0.30883967  0.83307456  0.17788357  0.36415364  0.6826063\n",
      " -0.71847156  0.39288254 -0.50307079 -0.87623958 -0.41764387  0.65352516\n",
      " -0.41698975  0.23282564 -0.16538816 -0.59660489 -0.91279927  0.11386634\n",
      " -0.36750312]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.43401632 -0.59772978 -0.76778616 -0.87289574  0.29759233  0.8586492\n",
      " -0.73371188  0.90479035 -0.32566997  0.45977333  0.33056279 -0.87636953\n",
      " -0.14028554  0.68909284  0.21300173 -0.09113027  0.16018387 -0.78413829\n",
      "  0.03212234 -0.76542109  0.59389113  0.15920858 -0.8123422  -0.90726366\n",
      " -0.09870351]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.30444565  0.36552482  0.05621425  0.24651105  0.60325879 -0.7825812\n",
      " -0.59908908  0.05747227 -0.11111713 -0.48147854 -0.14768335 -0.36017825\n",
      "  0.19583372 -0.42745963  0.47381699 -0.42488087  0.65193939  0.01703806\n",
      "  0.33858685 -0.22722791  0.06246612 -0.8335185  -0.75272647  0.82871826\n",
      " -0.23512983]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.29583809  0.65163383  0.24022802  0.02921462  0.23221241  0.03773384\n",
      "  0.37716858  0.57475721  0.79895654  0.68352082  0.69009743 -0.71525107\n",
      " -0.87600012 -0.51556471  0.94781135 -0.45087065 -0.27294185  0.46015805\n",
      "  0.55459757  0.46777548 -0.03888175 -0.56421387 -0.13887219 -0.80265029\n",
      "  0.82728017]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.85289239  0.43173322 -0.19251841 -0.13039359 -0.68621675 -0.26415541\n",
      "  0.70085112  0.50608199 -0.28303225  0.90628468  0.42734437  0.89848128\n",
      " -0.20250138  0.36288053 -0.23978211 -0.55523684 -0.30419692  0.39678557\n",
      "  0.42031556  0.24534317  0.6138263   0.52663278 -0.41843963 -0.44145321\n",
      " -0.53168534]\n",
      "Evaluating with parameters:\n",
      "x_ind: [-0.42516877  0.29145563 -0.42266634  0.65500448  0.70632478  0.98019624\n",
      " -0.18147543  0.84358221 -0.03897403 -0.00192139 -0.43363346  0.97188313\n",
      " -0.39495236 -0.60969388 -0.87105491 -0.33494328 -0.0639986   0.5216837\n",
      " -0.58881857 -0.03105735 -0.15302478 -0.39480192  0.61384031 -0.78142512\n",
      "  0.15522181]\n",
      "Evaluating with parameters:\n",
      "x_ind: [ 0.13911533  0.83290354  0.61863475  0.00779641  0.25450558  0.72372803\n",
      "  0.95978064 -0.57196427  0.80900828  0.52106273  0.19915732 -0.53001396\n",
      " -0.51928037  0.27967953  0.97594244 -0.29373385  0.2891112  -0.08509069\n",
      " -0.76820056 -0.64694179  0.60406546  0.97153214 -0.05242552 -0.48665435\n",
      " -0.27803694]\n",
      "Best parameters:       W1_00     W1_01     W1_02     W1_03     W1_10     W1_11     W1_12  \\\n",
      "0 -0.634777 -0.250277  0.637639  0.139236  0.797896  0.829147  0.502362   \n",
      "\n",
      "      W1_13     W1_20     W1_21  ...     W1_33      b1_0      b1_1      b1_2  \\\n",
      "0  0.202245  0.150736  0.424265  ...  0.220286 -0.990689  0.682896 -0.430601   \n",
      "\n",
      "       b1_3     W2_00     W2_01     W2_02     W2_03      b2_0  \n",
      "0 -0.457077  0.403836  0.736352 -0.575241  0.011556  0.390276  \n",
      "\n",
      "[1 rows x 25 columns]\n",
      "Best loss: 0.17677372176561218\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List, Tuple, Any, Dict\n",
    "from mcbo.optimizers.bo_builder import BoBuilder\n",
    "from mcbo.tasks.task_base import TaskBase\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "print(df.shape)\n",
    "df = df.dropna(subset=['Age', 'Fare', 'Sex'])\n",
    "target_var = df.Survived\n",
    "print(df.shape)\n",
    "\n",
    "df = df[['Sex','Age', 'Fare']]\n",
    "encode_cat_var = pd.get_dummies(df['Sex'])\n",
    "df = df.drop(['Sex'], axis =1)\n",
    "X = pd.concat([encode_cat_var, df], axis = 1)\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns) \n",
    "\n",
    "y = target_var\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Activation functions\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "def softmax(Z):\n",
    "    return np.exp(Z) / np.sum(np.exp(Z))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Loss function\n",
    "def categorical_cross_entropy_batch(y_true_batch, y_pred_batch):\n",
    "    epsilon = 1e-15\n",
    "    y_pred_batch = np.clip(y_pred_batch, epsilon, 1 - epsilon)\n",
    "    ce_batch = -np.sum(y_true_batch * np.log(y_pred_batch), axis=1)\n",
    "    average_ce = np.mean(ce_batch)\n",
    "    return average_ce\n",
    "\n",
    "# Feed-forward ANN\n",
    "def forward_prop(W1, b1, W2, b2, X_data):\n",
    "    n_features = X_data.shape[1]\n",
    "    if W1.shape[1] != n_features:\n",
    "        W1_shape_0 = W1.size / n_features \n",
    "        W1 = np.reshape(W1_shape_0 ,n_features)\n",
    "    if W2.shape[1] != W1.shape[0]:\n",
    "        W2_shape_0 = W2.size / W1.shape[0]\n",
    "        W2 = np.reshape((W2_shape_0, W1.shape[0]))\n",
    "    Z1 = np.dot(W1, X_data.T) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2).T \n",
    "    return A2\n",
    "\n",
    "# Evaluation function\n",
    "def black_box_function(W1, b1, W2, b2):\n",
    "    result = forward_prop(W1, b1, W2, b2, X_train)\n",
    "    y_train_encoded = np.eye(2)[y_train]\n",
    "    return categorical_cross_entropy_batch(y_train_encoded, result)\n",
    "\n",
    "class CustomTask(TaskBase):\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return 'Custom Task'\n",
    "\n",
    "    def evaluate(self, x: np.ndarray) -> np.ndarray:\n",
    "        y = np.zeros((len(x), 1))\n",
    "        for ind in range(len(x)):\n",
    "            x_ind = x.iloc[ind].to_numpy()  # Convert Series to NumPy array\n",
    "            print(\"Evaluating with parameters:\")\n",
    "            print(\"x_ind:\", x_ind)\n",
    "            y[ind] = black_box_function(x_ind[:16].reshape(4, 4), x_ind[16:20].reshape(4, 1), x_ind[20:24].reshape(1, 4), x_ind[24:])\n",
    "        return y\n",
    "\n",
    "    \n",
    "    def get_search_space_params(self) -> List[Dict[str, Any]]:\n",
    "        params = [{'name': f'W1_{i}{j}', 'type': 'num', 'lb': -1, 'ub': 1} for i in range(4) for j in range(4)]\n",
    "        params.extend([{'name': f'b1_{i}', 'type': 'num', 'lb': -1, 'ub': 1} for i in range(4)])\n",
    "        params.extend([{'name': f'W2_{i}{j}', 'type': 'num', 'lb': -1, 'ub': 1} for i in range(1) for j in range(4)])\n",
    "        params.extend([{'name': f'b2_{i}', 'type': 'num', 'lb': -1, 'ub': 1} for i in range(1)])\n",
    "        return params\n",
    "\n",
    "    def get_parameter_names(self) -> List[str]:\n",
    "        params = []\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                params.append(f'W1_{i}{j}')\n",
    "        params.extend([f'b1_{i}' for i in range(4)])\n",
    "        for i in range(1):\n",
    "            for j in range(4):\n",
    "                params.append(f'W2_{i}{j}')\n",
    "        params.extend([f'b2_{i}' for i in range(1)])\n",
    "        return params\n",
    "\n",
    "# Creating task and optimization\n",
    "task = CustomTask()\n",
    "searchspace = task.get_search_space()\n",
    "\n",
    "bo_builder = BoBuilder(model_id='gp_rd', acq_opt_id='is', acq_func_id='ei', tr_id='basic')\n",
    "opt = bo_builder.build_bo(search_space=task.get_search_space(), n_init=50)\n",
    "\n",
    "# Optimization loop\n",
    "budget_eval = 50\n",
    "# Inside the optimization loop\n",
    "for _ in range(budget_eval):\n",
    "    x_next = opt.suggest()\n",
    "    x_next_reshaped = np.array(x_next).reshape(1, -1)  # Reshape x_next to have shape (1, 25)\n",
    "    x_next_df = pd.DataFrame(x_next_reshaped, columns=task.get_parameter_names())\n",
    "    y_next = task.evaluate(x_next_df)\n",
    "    opt.observe(x_next, y_next)\n",
    "\n",
    "    \n",
    "# Printing best result\n",
    "print('Best parameters:', opt.best_x)\n",
    "print('Best loss:', opt.best_y)\n",
    "\n",
    "# Plotting version\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "y = opt.data_buffer.y.numpy()\n",
    "regret_y = np.min(np.cumsum(y, axis=1), axis=0)\n",
    "#plt.plot(np.arange(1,  budget_eval ), regret_y)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "44e0af21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W1_00</th>\n",
       "      <th>W1_01</th>\n",
       "      <th>W1_02</th>\n",
       "      <th>W1_03</th>\n",
       "      <th>W1_10</th>\n",
       "      <th>W1_11</th>\n",
       "      <th>W1_12</th>\n",
       "      <th>W1_13</th>\n",
       "      <th>W1_20</th>\n",
       "      <th>W1_21</th>\n",
       "      <th>...</th>\n",
       "      <th>W1_33</th>\n",
       "      <th>b1_0</th>\n",
       "      <th>b1_1</th>\n",
       "      <th>b1_2</th>\n",
       "      <th>b1_3</th>\n",
       "      <th>W2_00</th>\n",
       "      <th>W2_01</th>\n",
       "      <th>W2_02</th>\n",
       "      <th>W2_03</th>\n",
       "      <th>b2_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.634777</td>\n",
       "      <td>-0.250277</td>\n",
       "      <td>0.637639</td>\n",
       "      <td>0.139236</td>\n",
       "      <td>0.797896</td>\n",
       "      <td>0.829147</td>\n",
       "      <td>0.502362</td>\n",
       "      <td>0.202245</td>\n",
       "      <td>0.150736</td>\n",
       "      <td>0.424265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220286</td>\n",
       "      <td>-0.990689</td>\n",
       "      <td>0.682896</td>\n",
       "      <td>-0.430601</td>\n",
       "      <td>-0.457077</td>\n",
       "      <td>0.403836</td>\n",
       "      <td>0.736352</td>\n",
       "      <td>-0.575241</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.390276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      W1_00     W1_01     W1_02     W1_03     W1_10     W1_11     W1_12  \\\n",
       "0 -0.634777 -0.250277  0.637639  0.139236  0.797896  0.829147  0.502362   \n",
       "\n",
       "      W1_13     W1_20     W1_21  ...     W1_33      b1_0      b1_1      b1_2  \\\n",
       "0  0.202245  0.150736  0.424265  ...  0.220286 -0.990689  0.682896 -0.430601   \n",
       "\n",
       "       b1_3     W2_00     W2_01     W2_02     W2_03      b2_0  \n",
       "0 -0.457077  0.403836  0.736352 -0.575241  0.011556  0.390276  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_weights_and_biases = dict(opt.best_x)\n",
    "opt.best_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dac74f8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-0.63477717, -0.2502768 ,  0.63763877,  0.13923594,  0.79789637,\n",
       "          0.82914736,  0.50236232,  0.20224478,  0.1507364 ,  0.42426497,\n",
       "         -0.58286194, -0.1376707 , -0.04467272, -0.8516601 , -0.44571432,\n",
       "          0.22028609]]),\n",
       " 'b1': array([[-0.99068884,  0.68289605, -0.43060141, -0.45707723]]),\n",
       " 'W2': array([[ 0.40383579,  0.73635211, -0.57524087,  0.01155575]]),\n",
       " 'b2': array([[0.39027595]])}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_and_biases_matrix(df_pars):\n",
    "    # Group the columns by their prefixes\n",
    "    grouped_columns = df_pars.columns.to_series().groupby(lambda x: x.split('_')[0], sort=False)\n",
    "\n",
    "    # Use dictionary comprehension to create the result dictionary\n",
    "   # result_arrays = {prefix: np.vstack([df_pars[cols].columns, df_pars[cols].values])\n",
    "    #                 for prefix, cols in grouped_columns.groups.items()}\n",
    "    result_arrays = {prefix: np.array(df_pars[cols].values)\n",
    "                     for prefix, cols in grouped_columns.groups.items()}\n",
    "\n",
    "    return result_arrays\n",
    "\n",
    "    #return weights_set_list#W1, weights_W2\n",
    "\n",
    "weights_and_biases_results = (weights_and_biases_matrix(opt.best_x))\n",
    "(weights_and_biases_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "879f2ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "478\n",
      "accuracy = 0.399581589958159\n"
     ]
    }
   ],
   "source": [
    "def forward_prop_adj(W1, b1, W2, b2, X_data):\n",
    "    n_features = X_data.shape[1]\n",
    "    if W1.shape[1] != n_features:\n",
    "        W1_shape_0 = int(W1.size / n_features) \n",
    "        W1 = np.reshape(W1, (W1_shape_0 ,n_features))\n",
    "    if W2.shape[1] != W1.shape[0]:\n",
    "        W2_shape_0 = int(W2.size / W1.shape[0])\n",
    "        W2 = np.reshape(W2, (W2_shape_0, W1.shape[0]))\n",
    "    Z1 = np.dot(W1, X_data.T) + b1.T\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2.T\n",
    "    A2 = sigmoid(Z2).T \n",
    "    return A2\n",
    "\n",
    "def binarize_outcome(res_arr):\n",
    "    return np.where(res_arr<.5,0,1)\n",
    "\n",
    "def calculate_accuracy(actual_val, pred_val):\n",
    "    correct = np.sum(actual_val == pred_val)\n",
    "    total = len(actual_val)\n",
    "    accuracy = correct / total\n",
    "    print(correct)\n",
    "    print(total)\n",
    "    return accuracy\n",
    "\n",
    "preds_train = forward_prop_adj(**weights_and_biases_results, X_data=X_train)\n",
    "binary_res = binarize_outcome(preds_train)\n",
    "print('accuracy =', calculate_accuracy(np.array(y_train), binary_res.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "37907a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "478\n",
      "accuracy = 0.399581589958159\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('accuracy =', calculate_accuracy(np.array(y_train), binary_res.flatten()))\n",
    "confusion_matrix = metrics.confusion_matrix(y_train, binary_res.flatten())\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "aabb8433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(binary_res.flatten())\n",
    "plt.plot(preds_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a4a4e171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83450927]\n",
      " [0.82700307]\n",
      " [0.84665296]\n",
      " [0.83937788]\n",
      " [0.84673905]\n",
      " [0.83504338]\n",
      " [0.84110691]\n",
      " [0.82046229]\n",
      " [0.83696235]\n",
      " [0.83374583]\n",
      " [0.82232967]\n",
      " [0.84449822]\n",
      " [0.83634729]\n",
      " [0.84000494]\n",
      " [0.83997268]\n",
      " [0.83503614]\n",
      " [0.82182766]\n",
      " [0.82960682]\n",
      " [0.83547213]\n",
      " [0.81828029]\n",
      " [0.83549592]\n",
      " [0.83166146]\n",
      " [0.81789581]\n",
      " [0.83301156]\n",
      " [0.84083703]\n",
      " [0.85744328]\n",
      " [0.82701795]\n",
      " [0.84849023]\n",
      " [0.83873839]\n",
      " [0.83863024]\n",
      " [0.85786081]\n",
      " [0.83760717]\n",
      " [0.84359576]\n",
      " [0.83886775]\n",
      " [0.83883666]\n",
      " [0.85226401]\n",
      " [0.83049917]\n",
      " [0.85042219]\n",
      " [0.82106058]\n",
      " [0.82768521]\n",
      " [0.83576497]\n",
      " [0.83141918]\n",
      " [0.84195401]\n",
      " [0.83419023]\n",
      " [0.8290028 ]\n",
      " [0.81922027]\n",
      " [0.84725549]\n",
      " [0.84194918]\n",
      " [0.8284286 ]\n",
      " [0.83043778]\n",
      " [0.83609996]\n",
      " [0.85278676]\n",
      " [0.83738219]\n",
      " [0.83418403]\n",
      " [0.83286798]\n",
      " [0.8398901 ]\n",
      " [0.83482116]\n",
      " [0.85079325]\n",
      " [0.83739871]\n",
      " [0.83118479]\n",
      " [0.83211914]\n",
      " [0.83095049]\n",
      " [0.836805  ]\n",
      " [0.84332072]\n",
      " [0.84113765]\n",
      " [0.82697532]\n",
      " [0.84145052]\n",
      " [0.82765015]\n",
      " [0.8322524 ]\n",
      " [0.84380081]\n",
      " [0.83374583]\n",
      " [0.8293922 ]\n",
      " [0.83261088]\n",
      " [0.83346867]\n",
      " [0.84271903]\n",
      " [0.84362809]\n",
      " [0.83286292]\n",
      " [0.83925831]\n",
      " [0.81816841]\n",
      " [0.83382824]\n",
      " [0.84114232]\n",
      " [0.83028526]\n",
      " [0.83079409]\n",
      " [0.83415371]\n",
      " [0.84052021]\n",
      " [0.83622955]\n",
      " [0.83028611]\n",
      " [0.85083   ]\n",
      " [0.85069667]\n",
      " [0.84145377]\n",
      " [0.85151122]\n",
      " [0.84450794]\n",
      " [0.84477478]\n",
      " [0.82091412]\n",
      " [0.81840468]\n",
      " [0.84099698]\n",
      " [0.83094419]\n",
      " [0.81940908]\n",
      " [0.8536085 ]\n",
      " [0.84252371]\n",
      " [0.83376361]\n",
      " [0.84268688]\n",
      " [0.84806079]\n",
      " [0.8302885 ]\n",
      " [0.84260208]\n",
      " [0.83364507]\n",
      " [0.82502454]\n",
      " [0.83966447]\n",
      " [0.83555038]\n",
      " [0.84604888]\n",
      " [0.81921356]\n",
      " [0.84449968]\n",
      " [0.81576773]\n",
      " [0.85955068]\n",
      " [0.86178037]\n",
      " [0.83855352]\n",
      " [0.83278202]\n",
      " [0.84076877]\n",
      " [0.83864042]\n",
      " [0.83799832]\n",
      " [0.85164994]\n",
      " [0.84828524]\n",
      " [0.82101255]\n",
      " [0.82568218]\n",
      " [0.83257882]\n",
      " [0.83430077]\n",
      " [0.84012042]\n",
      " [0.831301  ]\n",
      " [0.82896833]\n",
      " [0.8329273 ]\n",
      " [0.84014842]\n",
      " [0.84240637]\n",
      " [0.84116064]\n",
      " [0.8487143 ]\n",
      " [0.84424214]\n",
      " [0.82058071]\n",
      " [0.84183827]\n",
      " [0.84795012]\n",
      " [0.84360628]\n",
      " [0.84167317]\n",
      " [0.83382379]\n",
      " [0.82708343]\n",
      " [0.84732915]\n",
      " [0.83924086]\n",
      " [0.829721  ]\n",
      " [0.82465027]\n",
      " [0.81714095]\n",
      " [0.84612393]\n",
      " [0.84405365]\n",
      " [0.83483653]\n",
      " [0.83538221]\n",
      " [0.83546597]\n",
      " [0.85449071]\n",
      " [0.8505048 ]\n",
      " [0.83474498]\n",
      " [0.85418463]\n",
      " [0.83422038]\n",
      " [0.83286713]\n",
      " [0.82977435]\n",
      " [0.83882738]\n",
      " [0.83820726]\n",
      " [0.83590086]\n",
      " [0.82177551]\n",
      " [0.84675404]\n",
      " [0.83977772]\n",
      " [0.83981275]\n",
      " [0.84307217]\n",
      " [0.85384387]\n",
      " [0.83133565]\n",
      " [0.83613448]\n",
      " [0.82828861]\n",
      " [0.84044358]\n",
      " [0.83680362]\n",
      " [0.85749817]\n",
      " [0.85889173]\n",
      " [0.83966789]\n",
      " [0.84432845]\n",
      " [0.83886775]\n",
      " [0.83095491]\n",
      " [0.85263132]\n",
      " [0.83992007]\n",
      " [0.83224225]\n",
      " [0.84545551]\n",
      " [0.83101545]\n",
      " [0.85015372]\n",
      " [0.81574671]\n",
      " [0.8495893 ]\n",
      " [0.83884128]\n",
      " [0.84052021]\n",
      " [0.83926518]\n",
      " [0.84181993]\n",
      " [0.83747699]\n",
      " [0.84479843]\n",
      " [0.84904415]\n",
      " [0.84421746]\n",
      " [0.83236396]\n",
      " [0.84842483]\n",
      " [0.83239236]\n",
      " [0.83506217]\n",
      " [0.83928233]\n",
      " [0.84051553]\n",
      " [0.84300038]\n",
      " [0.83415002]\n",
      " [0.85108963]\n",
      " [0.83029652]\n",
      " [0.82053866]\n",
      " [0.84006121]\n",
      " [0.8218092 ]\n",
      " [0.83737393]\n",
      " [0.82594947]\n",
      " [0.84330211]\n",
      " [0.83226795]\n",
      " [0.83115251]\n",
      " [0.85161929]\n",
      " [0.83374583]\n",
      " [0.83673828]\n",
      " [0.83800595]\n",
      " [0.83303143]\n",
      " [0.83156174]\n",
      " [0.81691172]\n",
      " [0.84360628]\n",
      " [0.82729552]\n",
      " [0.83162957]\n",
      " [0.86316452]\n",
      " [0.83043778]\n",
      " [0.84246729]\n",
      " [0.8450644 ]\n",
      " [0.84276443]\n",
      " [0.83936612]\n",
      " [0.83633865]\n",
      " [0.83748886]\n",
      " [0.83578155]\n",
      " [0.8379838 ]\n",
      " [0.83700235]\n",
      " [0.83094419]\n",
      " [0.85048815]\n",
      " [0.85672344]\n",
      " [0.82527828]\n",
      " [0.83162738]\n",
      " [0.82430553]\n",
      " [0.85069147]\n",
      " [0.83224732]\n",
      " [0.83171436]\n",
      " [0.83093926]\n",
      " [0.8445159 ]\n",
      " [0.83165027]\n",
      " [0.84973935]\n",
      " [0.8196544 ]\n",
      " [0.83703114]\n",
      " [0.83030845]\n",
      " [0.8548287 ]\n",
      " [0.83797964]\n",
      " [0.85656919]\n",
      " [0.83353839]\n",
      " [0.83095049]\n",
      " [0.84205262]\n",
      " [0.83825986]\n",
      " [0.84175648]\n",
      " [0.85897128]\n",
      " [0.84542307]\n",
      " [0.82966175]\n",
      " [0.82191915]\n",
      " [0.84832248]\n",
      " [0.82364465]\n",
      " [0.84123973]\n",
      " [0.84735625]\n",
      " [0.84925642]\n",
      " [0.83801203]\n",
      " [0.83488844]\n",
      " [0.84554635]\n",
      " [0.83557   ]\n",
      " [0.83976973]\n",
      " [0.83162346]\n",
      " [0.86711216]\n",
      " [0.81812624]\n",
      " [0.82020025]\n",
      " [0.84419182]\n",
      " [0.83546597]\n",
      " [0.82710387]\n",
      " [0.8290156 ]\n",
      " [0.82998643]\n",
      " [0.83705554]\n",
      " [0.83736915]\n",
      " [0.85346538]\n",
      " [0.83986816]\n",
      " [0.83820726]\n",
      " [0.86388715]\n",
      " [0.84972023]\n",
      " [0.84136519]\n",
      " [0.85563298]\n",
      " [0.83936137]\n",
      " [0.83206466]\n",
      " [0.83189515]\n",
      " [0.834319  ]\n",
      " [0.83682382]\n",
      " [0.83681341]\n",
      " [0.8328941 ]\n",
      " [0.84380081]\n",
      " [0.84147185]\n",
      " [0.83438722]\n",
      " [0.84113633]\n",
      " [0.84542686]\n",
      " [0.84223584]\n",
      " [0.84422751]\n",
      " [0.83617168]\n",
      " [0.83832729]\n",
      " [0.83479911]\n",
      " [0.83813323]\n",
      " [0.83438915]\n",
      " [0.81574671]\n",
      " [0.84851042]\n",
      " [0.85786081]\n",
      " [0.8318764 ]\n",
      " [0.82966073]\n",
      " [0.84562998]\n",
      " [0.85068943]\n",
      " [0.85442596]\n",
      " [0.82966073]\n",
      " [0.84707234]\n",
      " [0.83289006]\n",
      " [0.84942284]\n",
      " [0.84071299]\n",
      " [0.82416215]\n",
      " [0.83610395]\n",
      " [0.83359367]\n",
      " [0.83755808]\n",
      " [0.85023907]\n",
      " [0.838524  ]\n",
      " [0.83773434]\n",
      " [0.82611114]\n",
      " [0.84934705]\n",
      " [0.85200153]\n",
      " [0.84301399]\n",
      " [0.83094419]\n",
      " [0.83311127]\n",
      " [0.83863123]\n",
      " [0.83156903]\n",
      " [0.84822195]\n",
      " [0.8418494 ]\n",
      " [0.85009007]\n",
      " [0.83062153]\n",
      " [0.83680362]\n",
      " [0.841741  ]\n",
      " [0.82743443]\n",
      " [0.82926537]\n",
      " [0.83286798]\n",
      " [0.82897122]\n",
      " [0.81892026]\n",
      " [0.82908349]\n",
      " [0.83489168]\n",
      " [0.83548688]\n",
      " [0.82230713]\n",
      " [0.84071299]\n",
      " [0.84451658]\n",
      " [0.85342501]\n",
      " [0.83480011]\n",
      " [0.83451111]\n",
      " [0.85399006]\n",
      " [0.83418001]\n",
      " [0.83673596]\n",
      " [0.8430139 ]\n",
      " [0.84114232]\n",
      " [0.83550808]\n",
      " [0.83339262]\n",
      " [0.85510274]\n",
      " [0.82959963]\n",
      " [0.83736816]\n",
      " [0.83377771]\n",
      " [0.85007126]\n",
      " [0.83345552]\n",
      " [0.84409067]\n",
      " [0.84501079]\n",
      " [0.84710405]\n",
      " [0.82453396]\n",
      " [0.83806924]\n",
      " [0.83636502]\n",
      " [0.82974646]\n",
      " [0.84498066]\n",
      " [0.84737738]\n",
      " [0.83221993]\n",
      " [0.86386184]\n",
      " [0.86787603]\n",
      " [0.81556632]\n",
      " [0.83743742]\n",
      " [0.84238482]\n",
      " [0.84695651]\n",
      " [0.84030469]\n",
      " [0.8586656 ]\n",
      " [0.82646558]\n",
      " [0.85056233]\n",
      " [0.85703795]\n",
      " [0.8607914 ]\n",
      " [0.83224445]\n",
      " [0.84102415]\n",
      " [0.85568411]\n",
      " [0.857285  ]\n",
      " [0.8354966 ]\n",
      " [0.83223954]\n",
      " [0.83672293]\n",
      " [0.84673629]\n",
      " [0.85324578]\n",
      " [0.83121369]\n",
      " [0.82860138]\n",
      " [0.83968434]\n",
      " [0.85324578]\n",
      " [0.84752504]\n",
      " [0.83596615]\n",
      " [0.82895307]\n",
      " [0.84185956]\n",
      " [0.83494237]\n",
      " [0.85068148]\n",
      " [0.83801203]\n",
      " [0.84238291]\n",
      " [0.83030676]\n",
      " [0.84446179]\n",
      " [0.83991975]\n",
      " [0.84226335]\n",
      " [0.82768625]\n",
      " [0.81699431]\n",
      " [0.83136896]\n",
      " [0.82898255]\n",
      " [0.85955274]\n",
      " [0.8619619 ]\n",
      " [0.8338341 ]\n",
      " [0.83266846]\n",
      " [0.8431026 ]\n",
      " [0.85607612]\n",
      " [0.82434513]\n",
      " [0.83459464]\n",
      " [0.83354007]\n",
      " [0.84125044]\n",
      " [0.82032845]\n",
      " [0.82568288]\n",
      " [0.83684332]\n",
      " [0.83855814]\n",
      " [0.83329511]\n",
      " [0.8471547 ]\n",
      " [0.83935666]\n",
      " [0.82492079]\n",
      " [0.83743676]\n",
      " [0.8461335 ]\n",
      " [0.83428871]\n",
      " [0.84665296]\n",
      " [0.85159225]\n",
      " [0.83481615]\n",
      " [0.83175504]\n",
      " [0.84429822]\n",
      " [0.83227656]\n",
      " [0.82083591]\n",
      " [0.83224208]\n",
      " [0.83252614]\n",
      " [0.84045964]\n",
      " [0.83503048]\n",
      " [0.82105702]\n",
      " [0.8549967 ]\n",
      " [0.83926403]\n",
      " [0.83191532]\n",
      " [0.83927008]\n",
      " [0.8329604 ]\n",
      " [0.82011469]\n",
      " [0.83546114]\n",
      " [0.82529398]\n",
      " [0.82646351]\n",
      " [0.84295835]\n",
      " [0.83290034]\n",
      " [0.83926518]\n",
      " [0.83224124]\n",
      " [0.83028238]\n",
      " [0.83290034]\n",
      " [0.85099501]\n",
      " [0.83424852]\n",
      " [0.8378331 ]\n",
      " [0.82499079]\n",
      " [0.8498374 ]\n",
      " [0.83503048]\n",
      " [0.84662694]\n",
      " [0.84038315]\n",
      " [0.8398901 ]]\n"
     ]
    }
   ],
   "source": [
    "print(preds_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe3876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
